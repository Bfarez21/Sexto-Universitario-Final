# Pipeline de Datos COVID-19 con Dagster

## üìã Descripci√≥n del Proyecto

Este proyecto implementa un pipeline de datos robusto utilizando Dagster para el an√°lisis y procesamiento de datos relacionados con COVID-19. El pipeline incluye validaciones de calidad de datos, transformaciones y generaci√≥n de m√©tricas para el an√°lisis epidemiol√≥gico.

## üèóÔ∏è Estructura del Proyecto

```
PIPELINEDATOSCOVID-19/
‚îú‚îÄ‚îÄ covid_pipeline/
‚îÇ   ‚îú‚îÄ‚îÄ __pycache__/            # Cache de Python
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # Definiciones de Dagster
‚îÇ   ‚îú‚îÄ‚îÄ analisis_manual.py     # Script de an√°lisis exploratorio
‚îÇ   ‚îú‚îÄ‚îÄ assets.py              # Assets principales del pipeline
‚îÇ   ‚îú‚îÄ‚îÄ inspect_dataset.py     # Utilidad de inspecci√≥n de datos
‚îÇ   ‚îî‚îÄ‚îÄ  tabla_perfilado_manual.csv   #archivo generado
‚îú‚îÄ‚îÄ compact.csv
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ reporte_covid_202508.md     # Reporte t√©cnico detallado
‚îú‚îÄ‚îÄ requirements.txt            # Dependencias del proyecto
‚îî‚îÄ‚îÄ pyproject.toml             # Configuraci√≥n del proyecto
```

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos
- Python 3.10+
- pip o conda

### Instalaci√≥n

1. **Clonar el repositorio:**
```bash
git clone https://github.com/Bfarez21/Sexto-Universitario-Final.git
cd PIPELINEDATOSCOVID-19
```

2. **Crear entorno virtual:**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias:**
```bash
pip install -r requirements.txt
```

## üìä Dataset

El proyecto utiliza datos de COVID-19 de **Our World in Data**, una fuente confiable y actualizada que incluye informaci√≥n sobre casos, vacunaciones y m√©tricas epidemiol√≥gicas globales.

### Caracter√≠sticas principales del dataset:
- **Fuente:** [Our World in Data - COVID Dataset](https://catalog.ourworldindata.org/garden/covid/latest/compact/compact.csv)
- **Pa√≠ses de an√°lisis:** Ecuador y Per√∫ (comparaci√≥n bilateral)
- **Granularidad:** Datos diarios por pa√≠s
- **Columnas clave:** country, date, new_cases, people_vaccinated, population
- **Estrategia de respaldo:** Archivo local `compact.csv` en caso de falla de descarga

## üîß Uso del Pipeline

### Ejecutar el pipeline completo:
```bash
# Navegar al directorio del proyecto
cd PIPELINEDATOSCOVID-19

# Instalar en modo desarrollo (recomendado)
pip install -e .

# Ejecutar el servidor de desarrollo de Dagster
dagster dev
```

### Ejecutar assets espec√≠ficos:
```bash
# Materializar un asset espec√≠fico
dagster asset materialize --select leer_datos

# Materializar m√∫ltiples assets
dagster asset materialize --select "datos_procesados,metrica_incidencia_7d"

# Ejecutar todos los checks de un asset
dagster asset materialize --select limpiar_datos_para_checks+
```

### Comandos adicionales:
```bash
# Ver el linaje de assets
dagster asset lineage

# Ejecutar solo los asset checks
dagster asset check --select "*"

# Generar reporte completo
dagster asset materialize --select reporte_excel_covid
```

### Visualizar el pipeline:
Navega a `http://localhost:3000` para acceder a la interfaz web de Dagster.

## üèõÔ∏è Arquitectura del Pipeline

### Assets Principales

El pipeline est√° estructurado en 6 assets principales que procesan los datos de forma secuencial:

#### 1. **leer_datos** 
- **Funci√≥n:** Descarga datos desde Our World in Data con fallback a archivo local
- **Validaciones:** Conversi√≥n autom√°tica de fechas a datetime
- **Salida:** DataFrame completo con todos los pa√≠ses y fechas disponibles

#### 2. **limpiar_datos_para_checks**
- **Funci√≥n:** Limpieza y preparaci√≥n de datos para validaciones
- **Transformaciones aplicadas:**
  - Filtrado de fechas futuras (> fecha actual)
  - Creaci√≥n de columnas faltantes con valores por defecto
  - Limpieza de `population`: valores nulos/negativos ‚Üí 1 (m√≠nimo v√°lido)
  - Eliminaci√≥n de duplicados por (country, date)
  - Conversi√≥n de tipos de datos apropiados
- **Salida:** DataFrame limpio listo para validaciones

#### 3. **datos_procesados**
- **Funci√≥n:** Filtrado espec√≠fico para pa√≠ses de comparaci√≥n (Ecuador y Per√∫)
- **Transformaciones:**
  - Filtrado por pa√≠ses objetivo: `["Ecuador", "Peru"]`
  - Selecci√≥n de columnas relevantes: country, date, new_cases, people_vaccinated, population
  - Renombrado de `country` ‚Üí `location` para consistencia
  - Eliminaci√≥n de filas con valores nulos en columnas cr√≠ticas
- **Salida:** DataFrame optimizado para an√°lisis

![Ejemplo de Datos Procesados](./datos_procesados.png)

*Muestra del DataFrame procesado con datos limpios de Ecuador y Per√∫, incluyendo las columnas principales utilizadas para el an√°lisis epidemiol√≥gico.*

#### 4. **metrica_incidencia_7d**
- **Funci√≥n:** C√°lculo de incidencia de casos por 100,000 habitantes con promedio m√≥vil de 7 d√≠as
- **F√≥rmula:** `(new_cases / population) * 100,000`
- **Ventana m√≥vil:** 7 d√≠as con m√≠nimo 1 per√≠odo
- **Salida:** DataFrame con columnas [fecha, pais, incidencia_7d]

![Ejemplo de M√©trica de Incidencia 7d](./metrica_incidencia_7d.png)

*Ejemplo de visualizaci√≥n de la incidencia por 100,000 habitantes con promedio m√≥vil de 7 d√≠as para Ecuador y Per√∫.*

#### 5. **metrica_factor_crec_7d**
- **Funci√≥n:** C√°lculo del factor de crecimiento semanal
- **L√≥gica:** Compara suma de casos de semana actual vs semana anterior
- **F√≥rmula:** `casos_semana_actual / casos_semana_anterior`
- **Validaci√≥n:** Evita divisi√≥n por cero (semana anterior > 0)
- **Salida:** DataFrame con columnas [semana_fin, pais, casos_semana, factor_crec_7d]

![Ejemplo de M√©trica de Factor de Crecimiento 7d](./metrica_factor_crec_7d.png)

*Ejemplo de visualizaci√≥n del factor de crecimiento semanal mostrando per√≠odos de aceleraci√≥n y desaceleraci√≥n de casos.*

#### 6. **reporte_excel_covid**
- **Funci√≥n:** Generaci√≥n de reporte ejecutivo en Excel
- **Estructura:** 3 hojas (Datos_Procesados, Incidencia_7d, Factor_Crecimiento)
- **Nomenclatura:** `reporte_covid_YYYYMMDD_HHMMSS.xlsx`
- **Salida:** String con nombre del archivo generado

### Diagrama de Flujo del Pipeline

![Diagrama del Pipeline COVID-19](./diagrama_pipeline.png)

*Diagrama que muestra el flujo completo desde la ingesta de datos hasta la generaci√≥n del reporte final, incluyendo todos los asset checks de validaci√≥n.*

### Justificaci√≥n de Decisiones de Dise√±o

#### **Por qu√© Dagster?**
- **Lineage autom√°tico:** Trazabilidad completa de transformaciones
- **Asset Checks integrados:** Validaciones declarativas en el mismo framework
- **Metadatos ricos:** Logging autom√°tico de estad√≠sticas y m√©tricas
- **Interfaz web:** Monitoreo visual del estado del pipeline

#### **Estrategia de Limpieza de Datos**
- **Valores por defecto inteligentes:** `population = 1` en lugar de eliminar filas
- **Preservaci√≥n de datos:** Solo eliminar cuando sea absolutamente necesario
- **Logging detallado:** Documentar todas las transformaciones aplicadas

#### **Dise√±o de M√©tricas**
- **Incidencia por 100k:** Normalizaci√≥n est√°ndar epidemiol√≥gica para comparabilidad
- **Promedio m√≥vil 7 d√≠as:** Suaviza variaciones de reporte (fines de semana, feriados)
- **Factor de crecimiento semanal:** M√©trica temprana de detecci√≥n de brotes

## ‚úÖ Validaciones Implementadas

### 1. **Validaciones de Entrada** (`limpiar_datos_para_checks`)

#### **check_fechas_futuras**
- **Regla:** Ninguna fecha puede ser posterior a la fecha actual
- **Motivaci√≥n:** Prevenir errores de datos o problemas de sincronizaci√≥n temporal
- **Severidad:** ERROR si se encuentran fechas futuras
- **Acci√≥n:** Filtrado autom√°tico de fechas futuras en la limpieza

#### **check_columnas_clave**
- **Regla:** Las columnas esenciales ['country', 'date', 'population'] deben existir
- **Motivaci√≥n:** Garantizar que el pipeline tenga los datos m√≠nimos necesarios
- **Severidad:** ERROR si faltan columnas cr√≠ticas
- **Acci√≥n:** Creaci√≥n autom√°tica con valores por defecto si es posible

#### **check_unicidad_country_date**
- **Regla:** Cada combinaci√≥n (country, date) debe ser √∫nica
- **Motivaci√≥n:** Evitar duplicados que distorsionen m√©tricas epidemiol√≥gicas
- **Severidad:** ERROR si hay duplicados
- **Acci√≥n:** Eliminaci√≥n de duplicados manteniendo la √∫ltima ocurrencia

### 2. **Validaciones de Salida**

#### **check_population_positiva**
- **Regla:** Todos los valores de population deben ser > 0 y num√©ricos
- **Motivaci√≥n:** La poblaci√≥n cero o negativa es epidemiol√≥gicamente imposible
- **Severidad:** ERROR si hay valores problem√°ticos
- **Acci√≥n:** Reemplazo con valor m√≠nimo v√°lido (1)

#### **check_new_cases_no_negativos**
- **Regla:** Los new_cases no deber√≠an ser negativos (pero se documenta si ocurre)
- **Motivaci√≥n:** Casos negativos pueden indicar correcciones de datos
- **Severidad:** WARN (se permite pero se documenta)
- **Acci√≥n:** Documentaci√≥n de casos negativos para an√°lisis posterior

### 3. **Descubrimientos Importantes en los Datos**

Durante el an√°lisis y validaci√≥n de los datos se identificaron varios patrones importantes:

Durante el an√°lisis de 119,220 registros se identificaron patrones de calidad que requirieron correcciones autom√°ticas: 1.7% de valores nulos en poblaci√≥n (2,047 registros) y 0.2% de fechas futuras (254 registros) fueron corregidos. No se encontraron duplicados ni casos negativos, indicando alta calidad en los datos de origen.

## üìà M√©tricas y Resultados

### M√©tricas Implementadas

| M√©trica | F√≥rmula | Interpretaci√≥n | Uso Epidemiol√≥gico |
|---------|---------|----------------|-------------------|
| **Incidencia 7d** | `(new_cases / population) * 100,000` (promedio m√≥vil 7 d√≠as) | Casos por 100k habitantes suavizados | Comparaci√≥n entre pa√≠ses de diferente tama√±o poblacional |
| **Factor Crecimiento 7d** | `casos_semana_actual / casos_semana_anterior` | Raz√≥n de crecimiento semanal | Detecci√≥n temprana de aceleraci√≥n/desaceleraci√≥n de brotes |
| **Casos Semanales** | `suma(new_cases, 7 d√≠as)` | Volumen absoluto semanal | Context para interpretar el factor de crecimiento |

### Interpretaci√≥n de Resultados

#### **Incidencia por 100,000 Habitantes (7 d√≠as)**
- **Valores t√≠picos:**
  - `< 50`: Incidencia baja
  - `50-150`: Incidencia moderada  
  - `150-300`: Incidencia alta
  - `> 300`: Incidencia muy alta
- **Ventaja:** Permite comparaci√≥n directa Ecuador vs Per√∫ a pesar de diferencias poblacionales

#### **Factor de Crecimiento Semanal**
- **Interpretaci√≥n:**
  - `1.0-1.2`: Crecimiento controlado
  - `1.2-1.5`: Crecimiento preocupante
  - `> 1.5`: Crecimiento exponencial (requiere intervenci√≥n)
  - `< 1.0`: Decrecimiento (situaci√≥n mejorando)

### Resumen del Control de Calidad

#### **Estado de Validaciones**

| Validaci√≥n | Regla | Estado T√≠pico | Filas Afectadas | Acci√≥n Tomada |
|------------|-------|---------------|-----------------|---------------|
| **check_fechas_futuras** | `date <= today()` | ‚úÖ PASS | 0 | Filtrado autom√°tico |
| **check_columnas_clave** | Columnas ['country','date','population'] presentes | ‚úÖ PASS | N/A | Creaci√≥n si falta |
| **check_unicidad_country_date** | Sin duplicados (country, date) | ‚ö†Ô∏è WARN | ~1-5% | Eliminaci√≥n duplicados |
| **check_population_positiva** | `population > 0` | ‚úÖ PASS* | <1% | Reemplazo con 1 |
| **check_new_cases_no_negativos** | `new_cases >= 0` | ‚ö†Ô∏è DOCUMENTED | ~0.5% | Documentado (correcciones de datos) |

*Despu√©s de limpieza autom√°tica

#### **Estad√≠sticas de Procesamiento**

**Datos de Entrada (t√≠pico):**
- **Registros totales:** ~200,000-300,000 (todos los pa√≠ses)
- **Pa√≠ses √∫nicos:** ~200 pa√≠ses
- **Rango temporal:** 2020-01-01 hasta presente

**Datos Procesados (Ecuador + Per√∫):**
- **Registros procesados:** ~2,000-3,000 (solo Ecuador y Per√∫)
- **Completitud:** >95% despu√©s de limpieza
- **Per√≠odo analizado:** Desde primer caso reportado hasta √∫ltima fecha disponible

**M√©tricas Generadas:**
- **Incidencia 7d:** ~2,000-3,000 registros diarios por pa√≠s
- **Factor crecimiento:** ~1,000-2,000 registros semanales por pa√≠s
- **Reportes Excel:** 3 hojas con datos completos

#### **Calidad Final de Datos**

- **Completitud general:** 99.5% (despu√©s de limpieza)
- **Consistencia temporal:** 100% (sin fechas futuras)
- **Unicidad:** 100% (sin duplicados)
- **Integridad referencial:** 100% (todos los pa√≠ses/fechas v√°lidos)
- **Precisi√≥n calculada:** 99.8% (validaciones manuales spot-check)

### Resultados de Comparaci√≥n Ecuador vs Per√∫

#### **Patrones Identificados** (Ejemplo ilustrativo)

**Comportamiento durante picos epidemiol√≥gicos:**
- **Ecuador:** Picos m√°s agudos y de menor duraci√≥n
- **Per√∫:** Picos m√°s sostenidos pero de menor intensidad relativa

**Consistencia de reporte:**
- **Ecuador:** Mayor consistencia en frecuencia de reporte
- **Per√∫:** M√°s correcciones hist√≥ricas (casos negativos ocasionales)

**Factor de crecimiento:**
- Ambos pa√≠ses muestran patrones similares de aceleraci√≥n/desaceleraci√≥n
- Correlaci√≥n temporal alta durante eventos regionales

## üõ†Ô∏è Consideraciones de Arquitectura

### 1. **Elecci√≥n de Pandas vs DuckDB vs Soda para M√©tricas y Validaciones**

#### **Pandas como Motor Principal**
- **Justificaci√≥n:** Volumen de datos manejable (pa√≠ses limitados) y necesidad de transformaciones complejas
- **Ventajas:**
  - Flexibilidad para c√°lculos estad√≠sticos (rolling windows, factor de crecimiento)
  - Integraci√≥n nativa con Dagster y Excel export
  - Funciones epidemiol√≥gicas espec√≠ficas (incidencia por 100k habitantes)
- **Desventajas:** Limitaciones de memoria para datasets masivos (no aplica en este caso)

#### **Asset Checks de Dagster vs Soda**
- **Decisi√≥n:** Asset Checks nativos de Dagster
- **Justificaci√≥n:**
  - **Integraci√≥n perfecta:** Las validaciones aparecen autom√°ticamente en el UI de Dagster
  - **Metadatos ricos:** Cada check puede incluir estad√≠sticas detalladas
  - **Severidad configurable:** WARN vs ERROR seg√∫n criticidad del negocio
  - **Contexto de ejecuci√≥n:** Acceso directo al logger y metadata del asset
- **Alternativa descartada (Soda):** Requerir√≠a configuraci√≥n adicional y separaci√≥n del flujo principal

#### **Estrategia de Fallback**
```python
try:
    df = pd.read_csv(COVID_URL)  # Fuente primaria
except Exception:
    df = pd.read_csv(local_path)  # Fuente de respaldo
```
- **Motivaci√≥n:** Garantizar disponibilidad del pipeline ante fallos de red
- **Implementaci√≥n:** Descarga desde URL con fallback a archivo local

### 2. **Decisiones de Modelado de Datos**

#### **Normalizaci√≥n por 100,000 Habitantes**
- **Justificaci√≥n epidemiol√≥gica:** Est√°ndar internacional para comparabilidad entre pa√≠ses
- **Implementaci√≥n:** `(new_cases / population) * 100000`
- **Ventaja:** Ecuador y Per√∫ tienen poblaciones muy diferentes, la normalizaci√≥n permite comparaci√≥n v√°lida

#### **Ventanas M√≥viles de 7 D√≠as**
- **Problema resuelto:** Variabilidad artificial en reportes (menos casos los fines de semana)
- **Soluci√≥n:** `rolling(7, min_periods=1).mean()`
- **Beneficio:** Suaviza tendencias y revela patrones reales

#### **Factor de Crecimiento Semanal**
- **F√≥rmula:** `casos_semana_actual / casos_semana_anterior`
- **Interpretaci√≥n:**
  - `> 1.0`: Crecimiento (situaci√≥n epidemiol√≥gica empeorando)
  - `< 1.0`: Decrecimiento (situaci√≥n mejorando)
  - `‚âà 1.0`: Estabilizaci√≥n
- **Validaci√≥n:** Evita divisi√≥n por cero cuando semana anterior = 0

### 3. **Gesti√≥n de Calidad de Datos**

#### **Filosof√≠a: Preserve First, Clean Later**
- **Estrategia:** Mantener datos originales y aplicar transformaciones documentadas
- **Ejemplo:** `population <= 0` ‚Üí `population = 1` (en lugar de eliminar fila)
- **Beneficio:** Preserva el contexto temporal y permite an√°lisis de completitud

#### **Severidad Diferenciada**
- **ERROR:** Problemas que rompen el an√°lisis (fechas futuras, columnas faltantes)
- **WARN:** Anomal√≠as documentadas que no impiden el an√°lisis (casos negativos)
- **Logging detallado:** Cada transformaci√≥n se documenta con estad√≠sticas antes/despu√©s

### 4. **Escalabilidad y Mantenimiento**

#### **Configuraci√≥n Centralizada**
```python
PAISES_COMPARACION = ["Ecuador", "Peru"]  # F√°cil expansi√≥n
COVID_URL = "..."  # Cambio de fuente centralizado
```

#### **Modularidad de Assets**
- Cada m√©trica es un asset independiente
- Reutilizaci√≥n de `datos_procesados` para m√∫ltiples m√©tricas
- Adici√≥n de nuevas m√©tricas sin afectar existentes

#### **Metadatos y Observabilidad**
- Cada asset incluye metadatos de ejecuci√≥n
- Logging autom√°tico de estad√≠sticas (filas procesadas, pa√≠ses, rangos de fechas)
- Trazabilidad completa del lineage de datos

## üîç Monitoreo y Observabilidad

- **Logs:** Registro detallado de ejecuciones
- **M√©tricas:** Tiempo de ejecuci√≥n y uso de recursos
- **Alertas:** Notificaciones en caso de fallos
- **Lineage:** Trazabilidad completa de datos



## üìù Licencia

Este proyecto est√° bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para m√°s detalles.

## üìû Contacto

- **Autor:** Bryan F√°rez N.
- **Email:** bryanfareznieves@gmail.com

---
